{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automotive-butler",
   "metadata": {},
   "source": [
    "# Reddit Mental Health Data Using Spark NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unavailable-pillow",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('spark_ml').config(\"spark.driver.memory\",\"8G\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-saudi",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-wisconsin",
   "metadata": {},
   "source": [
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3992cf22-0af8-4a4d-bb27-862bdf82a4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit = spark.read.options(delimiter=',', header=True, inferSchema=True, multiLine = True, escape = '\\\"').csv('mental_disorders_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe39f8fc-55dd-48e0-9d41-2d58c71aef92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- created_utc: integer (nullable = true)\n",
      " |-- over_18: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdbda3cf-9d30-4600-b450-482c203720d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+-------+---------+\n",
      "|               title|            selftext|created_utc|over_18|subreddit|\n",
      "+--------------------+--------------------+-----------+-------+---------+\n",
      "|Life is so pointl...|Does anyone else ...| 1650356960|  false|      BPD|\n",
      "|          Cold rage?|Hello fellow frie...| 1650356660|  false|      BPD|\n",
      "|I don’t know who ...|My [F20] bf [M20]...| 1650355379|  false|      BPD|\n",
      "|HELP! Opinions! A...|Okay, I’m about t...| 1650353430|  false|      BPD|\n",
      "|                help|           [removed]| 1650350907|  false|      BPD|\n",
      "|My ex got diagnos...|Without going int...| 1650350635|  false|      BPD|\n",
      "|Is misdiagnosis o...|(Reposting here o...| 1650349446|  false|      BPD|\n",
      "|I have trouble id...|I grew up mostly ...| 1650349125|  false|      BPD|\n",
      "|     Needing advice…|I posted on this ...| 1650349094|  false|      BPD|\n",
      "|      Do I have BPD?|           [removed]| 1650349072|   true|      BPD|\n",
      "|How do you deal w...|If they were to t...| 1650346904|  false|      BPD|\n",
      "|My husband doesn’...|I am in a really ...| 1650346237|  false|      BPD|\n",
      "|Not sure when my ...|My appointment wi...| 1650345499|  false|      BPD|\n",
      "|       anyone else??|Hi guys whenever ...| 1650345442|  false|      BPD|\n",
      "|Murderous Rage ki...|I have been actua...| 1650344955|   true|      BPD|\n",
      "|Where do I go fro...|So within the pas...| 1650343475|  false|      BPD|\n",
      "|Well I’m really f...|Two days ago I po...| 1650343263|  false|      BPD|\n",
      "|            it hurts|it fucking hurts\\...| 1650343073|  false|      BPD|\n",
      "|    it fucking hurts|           [removed]| 1650342953|  false|      BPD|\n",
      "|Saviour complex c...|Is it overcompens...| 1650340519|  false|      BPD|\n",
      "|different between...|the other day my ...| 1650339813|  false|      BPD|\n",
      "|realized i massiv...|idk what to do he...| 1650339777|  false|      BPD|\n",
      "|Birthdays are wei...|Does anyone else ...| 1650338795|  false|      BPD|\n",
      "|Birthdays are wei...|           [removed]| 1650338545|  false|      BPD|\n",
      "|How to stop talki...|Sorry if the form...| 1650337160|  false|      BPD|\n",
      "|fp just broke up ...|every day I relax...| 1650335264|  false|      BPD|\n",
      "|unstable identity...|           [removed]| 1650333780|  false|      BPD|\n",
      "|What is the point...|If I could push a...| 1650333404|  false|      BPD|\n",
      "|New FP after ONE ...|           [removed]| 1650333263|  false|      BPD|\n",
      "|FP is seriously d...|           [removed]| 1650333105|  false|      BPD|\n",
      "+--------------------+--------------------+-----------+-------+---------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d586dfe8-86a4-446b-80b8-e1127f55a5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime, date_format\n",
    "\n",
    "reddit = reddit.withColumn(\"date\", from_unixtime(\"created_utc\").cast(\"date\")) \\\n",
    "                         .withColumn(\"date_string\", date_format(\"date\", \"MM-dd-yyyy\")) \\\n",
    "                         .drop(\"date\", \"created_utc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1875e0-3107-4005-a4e9-85f82cc9d698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+---------+-----------+\n",
      "|               title|            selftext|over_18|subreddit|date_string|\n",
      "+--------------------+--------------------+-------+---------+-----------+\n",
      "|Life is so pointl...|Does anyone else ...|  false|      BPD| 04-19-2022|\n",
      "|          Cold rage?|Hello fellow frie...|  false|      BPD| 04-19-2022|\n",
      "|I don’t know who ...|My [F20] bf [M20]...|  false|      BPD| 04-19-2022|\n",
      "|HELP! Opinions! A...|Okay, I’m about t...|  false|      BPD| 04-19-2022|\n",
      "|                help|           [removed]|  false|      BPD| 04-19-2022|\n",
      "|My ex got diagnos...|Without going int...|  false|      BPD| 04-19-2022|\n",
      "|Is misdiagnosis o...|(Reposting here o...|  false|      BPD| 04-19-2022|\n",
      "|I have trouble id...|I grew up mostly ...|  false|      BPD| 04-19-2022|\n",
      "|     Needing advice…|I posted on this ...|  false|      BPD| 04-19-2022|\n",
      "|      Do I have BPD?|           [removed]|   true|      BPD| 04-19-2022|\n",
      "|How do you deal w...|If they were to t...|  false|      BPD| 04-19-2022|\n",
      "|My husband doesn’...|I am in a really ...|  false|      BPD| 04-19-2022|\n",
      "|Not sure when my ...|My appointment wi...|  false|      BPD| 04-19-2022|\n",
      "|       anyone else??|Hi guys whenever ...|  false|      BPD| 04-19-2022|\n",
      "|Murderous Rage ki...|I have been actua...|   true|      BPD| 04-19-2022|\n",
      "|Where do I go fro...|So within the pas...|  false|      BPD| 04-19-2022|\n",
      "|Well I’m really f...|Two days ago I po...|  false|      BPD| 04-19-2022|\n",
      "|            it hurts|it fucking hurts\\...|  false|      BPD| 04-19-2022|\n",
      "|    it fucking hurts|           [removed]|  false|      BPD| 04-19-2022|\n",
      "|Saviour complex c...|Is it overcompens...|  false|      BPD| 04-19-2022|\n",
      "|different between...|the other day my ...|  false|      BPD| 04-19-2022|\n",
      "|realized i massiv...|idk what to do he...|  false|      BPD| 04-19-2022|\n",
      "|Birthdays are wei...|Does anyone else ...|  false|      BPD| 04-19-2022|\n",
      "|Birthdays are wei...|           [removed]|  false|      BPD| 04-19-2022|\n",
      "|How to stop talki...|Sorry if the form...|  false|      BPD| 04-19-2022|\n",
      "|fp just broke up ...|every day I relax...|  false|      BPD| 04-19-2022|\n",
      "|unstable identity...|           [removed]|  false|      BPD| 04-19-2022|\n",
      "|What is the point...|If I could push a...|  false|      BPD| 04-19-2022|\n",
      "|New FP after ONE ...|           [removed]|  false|      BPD| 04-19-2022|\n",
      "|FP is seriously d...|           [removed]|  false|      BPD| 04-19-2022|\n",
      "+--------------------+--------------------+-------+---------+-----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e817b0-1fee-4487-895c-8c2933500180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53baf309-911e-4fbe-9747-13ea81048ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit = reddit.withColumn(\"subreddit\", regexp_replace(reddit[\"subreddit\"], \"bipolar\", \"BIPOLAR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e582ce-e6f7-4c12-ba7c-e17139077b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit = reddit.repartition(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e37f608-785c-4bb7-a6e8-4fdb46fa980a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701787\n",
      "--- 48.8083758354187 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(reddit.count())\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7bd8a3-870e-4b6e-90ee-410d7b745f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e212b1e-c32c-474e-a877-17800098705b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2023.3.23)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c92dfa-6d7b-415a-a955-07c181569054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import textblob\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04311ca-0d11-4a18-b7ef-1fbc6ad157eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col, udf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c60a3c-faba-4808-b2ec-a37b698d53f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handle null values in clean_freetext column\n",
    "def replace_null(x):\n",
    "    if x is None:\n",
    "        return ''\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "786b8014-bc56-4070-8d1b-597e312e2e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_null_udf = udf(replace_null, StringType())\n",
    "reddit = reddit.withColumn('selftext', replace_null_udf(col('selftext')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a9798b-0ae9-4c9c-86a7-4ae62996c0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove stopwords from freetext column\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filter_spam = F.udf(lambda x: \" \".join([word for word in x.lower().split() if word not in stop_words]), StringType())\n",
    "reddit = reddit.withColumn('clean_selftext', filter_spam(col('selftext')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3efd484b-01e4-48a6-8a3e-bf9ad97bae40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove stopwords from Title column\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filter_spam = F.udf(lambda x: \" \".join([word for word in x.lower().split() if word not in stop_words]), StringType())\n",
    "reddit = reddit.withColumn('clean_title', filter_spam(col('title')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad2ab32-dd2f-449d-b5db-786bd71d4270",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+-------------+-----------+--------------------+--------------------+\n",
      "|               title|            selftext|over_18|    subreddit|date_string|      clean_selftext|         clean_title|\n",
      "+--------------------+--------------------+-------+-------------+-----------+--------------------+--------------------+\n",
      "|He’s not coming b...|I’m in legal trou...|  false|          BPD| 11-04-2021|i’m legal trouble...|he’s coming back ...|\n",
      "|Does anyone else ...|My fp is my bf an...|  false|          BPD| 06-18-2021|fp bf he’s amazin...|anyone else try a...|\n",
      "|Do you also demon...|In my opinion, wh...|  false|          BPD| 06-29-2018|opinion, love man...|also demonize per...|\n",
      "|Idk what's wrong ...|Recently I've wen...|  false|   depression| 06-24-2022|recently i've wen...|idk what's wrong me.|\n",
      "|             Analagy|\\nI came up with ...|  false|   depression| 05-02-2022|came analogy make...|             analagy|\n",
      "|my gf is suddenly...|i don't even use ...|  false|   depression| 09-25-2022|even use redit mu...|gf suddenly movin...|\n",
      "|8 months later an...|I have a history/...|  false|      Anxiety| 05-08-2022|history/pattern r...|8 months later st...|\n",
      "|DAE have trouble ...|For a long time n...|  false|          BPD| 11-11-2020|long time i've tr...|dae trouble finis...|\n",
      "|Is it normal to d...|I've read on dysf...|  false|          BPD| 03-15-2021|i've read dysfunc...|normal develop in...|\n",
      "|So I have a menta...|I have dissociati...|  false|mentalillness| 04-30-2021|dissociation. con...|mental problem. h...|\n",
      "+--------------------+--------------------+-------+-------------+-----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba440b1c-0c51-43ab-933f-93ee55a7e2b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Word Counts of the 'SelfText' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1852453e-b338-4267-aae1-888ddf54bbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|  word| count|\n",
      "+------+------+\n",
      "|  like|720840|\n",
      "|  feel|578344|\n",
      "|   i'm|521733|\n",
      "|   i’m|471377|\n",
      "|  know|404265|\n",
      "|   get|372578|\n",
      "|  want|346615|\n",
      "|really|313670|\n",
      "|  even|308379|\n",
      "|people|234724|\n",
      "+------+------+\n",
      "\n",
      "--- 64.29725623130798 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Split the lines into words\n",
    "words = reddit.select(fn.explode(fn.split(fn.concat_ws(\" \", reddit.clean_selftext), ' ')).alias('word'))\n",
    "\n",
    "#Generate word count\n",
    "word_counts = words.groupBy('word').count()\n",
    "\n",
    "# Sort by count in descending order and take the top 10\n",
    "top10 = word_counts.orderBy('count', ascending=False).limit(10)\n",
    "\n",
    "top10.show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcacd5d1-4c85-44bb-a71b-37eed6b46e23",
   "metadata": {},
   "source": [
    "### Word Counts of the 'Title' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "033d2ba7-7d19-48b0-87fe-644713293006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "reddit = reddit.filter(fn.col(\"title\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbd9d0e8-6a0b-4c4a-b9d2-0c69a88ae4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701741"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e1d9d7b-c8b0-419f-a1df-62ef84581a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  word2|count|\n",
      "+-------+-----+\n",
      "|   feel|46177|\n",
      "|anxiety|45834|\n",
      "|   like|37183|\n",
      "| anyone|35617|\n",
      "|    i'm|32209|\n",
      "|    i’m|31356|\n",
      "|    bpd|27480|\n",
      "|    get|25525|\n",
      "|   help|24560|\n",
      "|   need|21865|\n",
      "+-------+-----+\n",
      "\n",
      "--- 49.3799889087677 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Split the lines into words\n",
    "words2 = reddit.select(fn.explode(fn.split(fn.concat_ws(\" \", reddit.clean_title), ' ')).alias('word2'))\n",
    "\n",
    "#Generate word count\n",
    "word_counts2 = words2.groupBy('word2').count()\n",
    "\n",
    "# Sort by count in descending order and take the top 10\n",
    "top10_2 = word_counts2.orderBy('count', ascending=False).limit(10)\n",
    "\n",
    "top10_2.show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f370531-8af4-456e-940c-3fcc75bb8c55",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment Analysis of 'Self Text' grouped by Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcc70afb-2d08-46ad-9ae8-f5deadb1e0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark-3.3.1-bin-hadoop3/python (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2023.3.23)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install nltk\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0f05673-dc4c-4789-b18c-2b2588fcefda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate sentiment score of clean_freetext column\n",
    "get_sentiment = F.udf(lambda x: TextBlob(x).sentiment.polarity, StringType())\n",
    "reddit = reddit.withColumn('sentiment', get_sentiment(col('clean_selftext')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6544f01-9647-44c6-b02b-584e18b58177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- selftext: string (nullable = true)\n",
      " |-- over_18: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- date_string: string (nullable = true)\n",
      " |-- clean_selftext: string (nullable = true)\n",
      " |-- clean_title: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e64bab-7976-4cc7-a67b-b083e8d1a72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate sentiment score and label of clean_freetext column\n",
    "def get_sentiment(x):\n",
    "    if x:\n",
    "        score = TextBlob(x).sentiment.polarity\n",
    "        if score > 0:\n",
    "            return 'Positive'\n",
    "        elif score < 0:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed37473-76ab-475b-bb4a-454d85c3518a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_sentiment_udf = udf(get_sentiment, StringType())\n",
    "reddit = reddit.withColumn('sentiment_category', get_sentiment_udf(col('clean_selftext')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90945ffb-6014-49e9-b826-58b11f78192a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+-------------+-----------+--------------------+--------------------+--------------------+------------------+\n",
      "|               title|            selftext|over_18|    subreddit|date_string|      clean_selftext|         clean_title|           sentiment|sentiment_category|\n",
      "+--------------------+--------------------+-------+-------------+-----------+--------------------+--------------------+--------------------+------------------+\n",
      "|He’s not coming b...|I’m in legal trou...|  false|          BPD| 11-04-2021|i’m legal trouble...|he’s coming back ...| 0.15952380952380954|          Positive|\n",
      "|Does anyone else ...|My fp is my bf an...|  false|          BPD| 06-18-2021|fp bf he’s amazin...|anyone else try a...| 0.10833333333333332|          Positive|\n",
      "|Do you also demon...|In my opinion, wh...|  false|          BPD| 06-29-2018|opinion, love man...|also demonize per...| 0.04516369047619047|          Positive|\n",
      "|Idk what's wrong ...|Recently I've wen...|  false|   depression| 06-24-2022|recently i've wen...|idk what's wrong me.|-0.09603174603174602|          Negative|\n",
      "|             Analagy|\\nI came up with ...|  false|   depression| 05-02-2022|came analogy make...|             analagy| 0.04047619047619047|          Positive|\n",
      "|my gf is suddenly...|i don't even use ...|  false|   depression| 09-25-2022|even use redit mu...|gf suddenly movin...| 0.16579558652729381|          Positive|\n",
      "|8 months later an...|I have a history/...|  false|      Anxiety| 05-08-2022|history/pattern r...|8 months later st...|-0.19230639730639731|          Negative|\n",
      "|DAE have trouble ...|For a long time n...|  false|          BPD| 11-11-2020|long time i've tr...|dae trouble finis...|  0.2416666666666667|          Positive|\n",
      "|Is it normal to d...|I've read on dysf...|  false|          BPD| 03-15-2021|i've read dysfunc...|normal develop in...|              0.2125|          Positive|\n",
      "|So I have a menta...|I have dissociati...|  false|mentalillness| 04-30-2021|dissociation. con...|mental problem. h...| 0.03216964285714286|          Positive|\n",
      "+--------------------+--------------------+-------+-------------+-----------+--------------------+--------------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f5d4bef-6792-466c-b497-092db9666c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group by channel and sentiment and count the number of records\n",
    "sentiment_count = reddit.groupBy('subreddit', 'sentiment_category').count()\n",
    "\n",
    "# pivot the sentiment column and fill null values with 0\n",
    "sentiment_count = sentiment_count.groupBy('subreddit').pivot('sentiment_category', ['Negative', 'Neutral', 'Positive']).sum('count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebbe8a49-7ec8-4601-92d5-cde8e539b248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-------+--------+\n",
      "|    subreddit|Negative|Neutral|Positive|\n",
      "+-------------+--------+-------+--------+\n",
      "|      BIPOLAR|   13320|  13789|   19546|\n",
      "|          BPD|   88536|  33959|  110574|\n",
      "|   depression|   57201|  41203|   58302|\n",
      "|mentalillness|   17627|   8605|   18009|\n",
      "|      Anxiety|   77670|  12857|   76491|\n",
      "|schizophrenia|    4122|  10227|    5926|\n",
      "+-------------+--------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d79e13-e7da-4a70-945d-6f34df861d1d",
   "metadata": {},
   "source": [
    "### Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87d8864e-26af-4669-9564-e9b3efcc3881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split, regexp_extract, col, lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90ca3893-d132-404e-81b7-f2483cd210da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace special characters and punctuation with spaces and change text to lowercase\n",
    "reddit = reddit.withColumn(\"selftext_cleaned\", lower(regexp_replace(col(\"selftext\"), \"[^a-zA-Z0-9\\\\s.,?]+\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1be2a340-c426-49be-9d22-3db17b33e70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# Define a regular expression pattern to remove unwanted characters\n",
    "pattern = \"[\\n/]|r/\"\n",
    "\n",
    "# Apply the regular expression to the \"title\" and \"selftext\" columns and replace the matches with an empty string\n",
    "reddit = reddit.withColumn(\"title_cleaned\", regexp_replace(col(\"title\"), pattern, \"\"))\n",
    "reddit = reddit.withColumn(\"selftext_cleaned\", regexp_replace(col(\"selftext_cleaned\"), pattern, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcb745c4-68fd-40b2-833d-3f6367e5f8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# Replace the \")( \" characters with a comma\n",
    "reddit = reddit.withColumn(\"selftext_cleaned\", regexp_replace(col(\"selftext_cleaned\"), \"\\)\\(\\/)s\", \",\"))\n",
    "\n",
    "# Remove any remaining \")\" and \"(\" characters\n",
    "reddit = reddit.withColumn(\"selftext_cleaned\", regexp_replace(col(\"selftext_cleaned\"), \"[\\(\\)]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01e3c742-dad4-43b4-aea7-0dbbfbccc45e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'regexp_replace(selftext_cleaned, [.,!?], , 1)'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_replace(col(\"selftext_cleaned\"), \"[.,!?]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75686f6d-713a-4975-ab73-d85d6c829541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, regexp_replace, col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Define a function to remove punctuation marks from the cleaned text\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('',\"\" '',... '.,!?'))\n",
    "\n",
    "# Define a UDF to apply the remove_punctuation function to each row in the DataFrame\n",
    "remove_punctuation_udf = udf(remove_punctuation, StringType())\n",
    "\n",
    "# Clean the \"selftext\" column and remove punctuation marks\n",
    "reddit = reddit.withColumn(\"selftext_cleaned\", lower(regexp_replace(col(\"selftext\"), \"[^a-zA-Z0-9\\\\s]+\\nr/\", \" \")))\n",
    "reddit = reddit.withColumn(\"selftext_cleaned\", remove_punctuation_udf(col(\"selftext_cleaned\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00635da7-1635-4c6c-9976-69f42529eb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a regular expression pattern to match topics\n",
    "pattern = r\"(?i)\\b(anxiety|depression|bipolar|schizophrenia|PTSD|OCD|ADHD|autism|panic|stress)\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f9aa23b-7370-4d0e-9b70-9388d0f20b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the selftext column by whitespace and explode the resulting array\n",
    "exploded = reddit.select(\"subreddit\", explode(split(col(\"selftext_cleaned\"), \" \")).alias(\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa1feee8-a27f-45b8-91e5-a281918ae972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract topics using the regular expression pattern and group by subreddit and topic\n",
    "topics = exploded.filter(regexp_extract(col(\"word\"), pattern, 0) != \"\").groupBy(\"subreddit\", \"word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0663e6bb-6999-489b-a4d3-ee5c3db622d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the \"word\" column to \"topic\" and sort by subreddit and count\n",
    "topics = topics.withColumnRenamed(\"word\", \"topic\").orderBy(\"subreddit\", \"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c8946d3-7009-40b8-8dde-039c3d1e2fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----+\n",
      "|    subreddit|               topic|count|\n",
      "+-------------+--------------------+-----+\n",
      "|schizophrenia|       schizophrenia| 3548|\n",
      "|schizophrenia|             anxiety|  906|\n",
      "|schizophrenia|          depression|  512|\n",
      "|schizophrenia|              stress|  362|\n",
      "|schizophrenia|             bipolar|  352|\n",
      "|schizophrenia|                 ocd|  266|\n",
      "|schizophrenia|      schizophrenia”|  265|\n",
      "|schizophrenia|               panic|  241|\n",
      "|schizophrenia|                adhd|  181|\n",
      "|schizophrenia|              autism|  142|\n",
      "|schizophrenia|                ptsd|  138|\n",
      "|schizophrenia|      schizophrenia“|   23|\n",
      "|schizophrenia|      schizophrenia)|   21|\n",
      "|schizophrenia|     r/schizophrenia|   14|\n",
      "|schizophrenia|schizophrenia/sch...|   11|\n",
      "|schizophrenia|      schizophrenia\"|   11|\n",
      "|schizophrenia|psychosis/schizop...|    8|\n",
      "|schizophrenia|                ocd)|    8|\n",
      "|schizophrenia|     \\nschizophrenia|    7|\n",
      "|schizophrenia|              c-ptsd|    7|\n",
      "+-------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the resulting DataFrame\n",
    "topics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3f044-7c34-4804-83f3-07c9c3e36d12",
   "metadata": {},
   "source": [
    "### Length of the Post Using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "392cdad5-e986-42ef-a42f-a18e4ba18f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (67.1.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0973c2f5-6011-4810-a6a8-dfd964acebf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.1.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4d537de-ec84-4859-a6a2-4139b3ade46e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a function to calculate the length of a post\n",
    "def calculate_post_length(post):\n",
    "    doc = nlp(post)\n",
    "    num_tokens = len(doc)\n",
    "    return num_tokens\n",
    "\n",
    "# Define a UDF to apply the calculate_post_length function to each row in the DataFrame\n",
    "calculate_length_udf = udf(lambda x: calculate_post_length(x), IntegerType())\n",
    "\n",
    "# Calculate the length of each post and add a new column called \"post_length\"\n",
    "reddit = reddit.withColumn(\"post_length\", calculate_length_udf(col(\"selftext\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a7e34d1-922d-4530-a0e7-3b549bcffa53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            selftext|post_length|\n",
      "+--------------------+-----------+\n",
      "|What will help me...|         35|\n",
      "|i have autism and...|         99|\n",
      "|I’m in twelfth gr...|        238|\n",
      "|Is it normal to b...|         84|\n",
      "|something pretty ...|        540|\n",
      "|I’ve been having ...|         84|\n",
      "|Do you ever just ...|         89|\n",
      "|Recently I've not...|        423|\n",
      "|What are your exp...|        271|\n",
      "|I have had a bad ...|        102|\n",
      "|I had issues of d...|        164|\n",
      "|I don’t know how ...|        103|\n",
      "|I just conquered ...|         67|\n",
      "|I don't know if i...|        345|\n",
      "|So, my living sit...|        475|\n",
      "|I’m so fucking fr...|         60|\n",
      "|Someone I know wi...|         29|\n",
      "|Since my job invo...|         22|\n",
      "|I want to get a d...|         87|\n",
      "|I'm so tired of c...|        283|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a temporary view\n",
    "reddit.createOrReplaceTempView(\"reddit_view\")\n",
    "\n",
    "# Select the \"selftext\" and \"post_length\" columns from the temporary view\n",
    "result = spark.sql(\"SELECT selftext, post_length FROM reddit_view\")\n",
    "\n",
    "# Show the result\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bb8cf-499a-4f6b-9e7a-d6bd497bd15a",
   "metadata": {},
   "source": [
    "### Random Forest Classifier to predict the Subreddit based on the Post Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fab69f79-db49-4b0d-b8bb-2bc1549e1b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "\n",
    "# Sample 1% of the original dataset\n",
    "sampled_data = reddit.sample(fraction=0.01, seed=42)\n",
    "\n",
    "# Split the sampled data into training and test sets\n",
    "train_data, test_data = sampled_data \\\n",
    "    .withColumn(\"rand\", rand()) \\\n",
    "    .sort(\"rand\") \\\n",
    "    .select([\"selftext\", \"subreddit\", \"post_length\"]) \\\n",
    "    .randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# Cache the training and test data for faster processing\n",
    "train_data = train_data.cache()\n",
    "test_data = test_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43572f8b-7a9c-4ffe-91b4-7b0bf5e21238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35793357933579334\n",
      "F1 score: 0.3174856208785022\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "# Encode the subreddit column as a numerical label\n",
    "indexer = StringIndexer(inputCol=\"subreddit\", outputCol=\"label\")\n",
    "\n",
    "# Convert the features to a vector using VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"post_length\"], outputCol=\"features\")\n",
    "\n",
    "# Define a random forest classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Define a pipeline to chain the transformers and classifier\n",
    "pipeline = Pipeline(stages=[indexer, assembler, rf])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(predictions)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bffb78-abdb-4a43-898d-855479346af5",
   "metadata": {},
   "source": [
    "### Sentiment Scored by Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ffea829f-2bf0-4438-8f1f-e098e6fd6e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if text is None:\n",
    "        return []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    scores = []\n",
    "    for sentence in sentences:\n",
    "        score = TextBlob(sentence).sentiment.polarity\n",
    "        scores.append(score)\n",
    "    return scores if len(scores) > 0 else [0.0]\n",
    "\n",
    "get_sentiment_udf = udf(get_sentiment, FloatType())\n",
    "\n",
    "reddit = reddit.filter(col(\"selftext\").isNotNull()) # filter out null values in selftext column\n",
    "reddit = reddit.withColumn('sentiment_scores', get_sentiment_udf(col('selftext')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "192292c6-1fdf-492b-983c-16db1ebf233a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|selftext|sentiment_scores|\n",
      "+--------+----------------+\n",
      "+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a temporary view\n",
    "reddit.createOrReplaceTempView(\"reddit_sentiment\")\n",
    "\n",
    "# Select the \"selftext\" and \"sentiment_scores\" columns from the temporary view, filtering out null scores\n",
    "result = spark.sql(\"SELECT selftext, sentiment_scores FROM reddit_sentiment WHERE sentiment_scores IS NOT NULL\")\n",
    "\n",
    "# Show the result\n",
    "result.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
